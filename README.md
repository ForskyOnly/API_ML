Voici une version mise √† jour et int√©gr√©e du README, incorporant les informations sur le ML Ops et le dashboard :


# üöÄ API de Classification des Donn√©es √† Risque

## üìã Table des mati√®res
- [√Ä propos du projet](#√†-propos-du-projet)
- [Fonctionnalit√©s](#fonctionnalit√©s)
- [Pr√©requis](#pr√©requis)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [ML Ops et Dashboard](#ml-ops-et-dashboard)
- [D√©ploiement](#d√©ploiement)
- [Contribution](#contribution)
- [Licence](#licence)

## üéØ √Ä propos du projet

Ce projet est une API de classification des donn√©es √† risque, utilisant des mod√®les de machine learning pour pr√©dire le niveau de risque associ√© √† un texte donn√©.

## ‚ú® Fonctionnalit√©s

- üîç Classification de texte en temps r√©el
- üîê Authentification par cl√© API
- üìä Utilisation de mod√®les MLflow pour les pr√©dictions
- üê≥ Conteneurisation avec Docker pour un d√©ploiement facile
- üìà Dashboard interactif pour le suivi des performances des mod√®les

## üõ† Pr√©requis

- Python 3.9+
- Docker
- Compte Azure (pour le d√©ploiement)

## üöÄ Installation

1. Clonez le d√©p√¥t :
   ```
   git clone https://github.com/ForskyOnly/API_ML/.git
   cd api_ml
   ```

2. Cr√©ez un environnement virtuel :
   ```
   python -m venv venv
   source venv/bin/activate  # Sur Windows, utilisez `venv\Scripts\activate`
   ```

3. Installez les d√©pendances :
   ```
   pip install -r requirements.txt
   ```

4. Configurez les variables d'environnement :
   ```
   MLFLOW_TRACKING_URI= chemin vers le dossier mlruns
   BEST_RUN_ID= meilleir run id
   API_KEY= la clef api
   API_KEY_NAME=nom de l'api_key
   ```
   √âditez le fichier `.env` avec vos propres valeurs.

## üñ• Utilisation

Pour lancer l'API localement :

```
uvicorn api.app.main:app --reload
```

L'API sera accessible √† l'adresse `http://localhost:8000`.

## üõ† ML Ops et Dashboard

### MLflow

MLflow est utilis√© pour le suivi des exp√©riences, la gestion des mod√®les et le d√©ploiement.

Pour acc√©der √† l'interface MLflow, ex√©cutez :

```
mlflow ui
```

### Dashboard de Monitoring

Un dashboard interactif a √©t√© d√©velopp√© avec Streamlit pour visualiser les performances des mod√®les.

Pour lancer le dashboard :

```
streamlit run ml_ops/dashboard.py
```

#### Fonctionnalit√©s principales du dashboard :

1. S√©lection du mod√®le
2. Affichage des meilleurs param√®tres
3. Visualisation des m√©triques (pr√©cision, rappel, score F1)
4. Analyse du drift
5. Matrice de confusion
6. Comparaison des mod√®les
7. Historique des runs

### Int√©gration Continue / D√©ploiement Continu (CI/CD)

Nous utilisons GitHub Actions pour automatiser les tests, la construction des images Docker et le d√©ploiement sur Azure.

### Monitoring en Production

- Logs : Utilisation du logging Python standard, captur√© et g√©r√© par Azure.
- Alertes : Configur√©es dans Azure pour notifier en cas de probl√®mes.

## üåê D√©ploiement

1. Construisez l'image Docker :
   ```
   docker build -t votre-image:tag .
   ```

2. Poussez l'image vers Azure Container Registry :
   ```
   docker push votre-acr.azurecr.io/votre-image:tag
   ```

3. D√©ployez sur Azure Container Instances en utilisant le portail Azure ou Azure CLI.

4. Configurez les variables d'environnement dans Azure :
   - API_KEY
   - API_KEY_NAME
   - MLFLOW_TRACKING_URI
   - BEST_RUN_ID

## ü§ù Contribution

Les contributions sont les bienvenues ! Consultez le fichier `CONTRIBUTING.md` pour plus d'informations.

## üìÑ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de d√©tails.


